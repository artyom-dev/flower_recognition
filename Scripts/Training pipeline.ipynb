{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3927cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opendatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15d47",
   "metadata": {},
   "source": [
    "# Install needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a28c26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import PIL \n",
    "import opendatasets as od \n",
    "from torchvision import datasets, transforms\n",
    "import os \n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch \n",
    "import torchvision \n",
    "import wandb\n",
    "from torch import nn \n",
    "from torchvision.models import resnet34\n",
    "from tqdm import tqdm  \n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import precision_recall\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchmetrics import MatthewsCorrCoef, Specificity, F1Score, CohenKappa\n",
    "from torch.utils.data import TensorDataset\n",
    "from collections import OrderedDict\n",
    "import splitfolders\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8339757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3cfe084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad909519",
   "metadata": {},
   "source": [
    "# Download and split data on train and test (Copied from EDA notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#od.download('https://www.kaggle.com/datasets/alxmamaev/flowers-recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a7cdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(dataset_obj):\n",
    "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
    "    \n",
    "    for element in dataset_obj:\n",
    "        y_lbl = element[1]\n",
    "        y_lbl = idx2class[y_lbl]\n",
    "        count_dict[y_lbl] += 1\n",
    "            \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "934cd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution_loaders(dataloader_obj, dataset_obj):\n",
    "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
    "    \n",
    "    for _,j in dataloader_obj:\n",
    "        y_idx = j.item()\n",
    "        y_lbl = idx2class[y_idx]\n",
    "        count_dict[str(y_lbl)] += 1\n",
    "            \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1809b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of classes: \n",
      " {'daisy': 764, 'dandelion': 1052, 'rose': 784, 'sunflower': 733, 'tulip': 984}\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"../Task/flowers-recognition/flowers\"\n",
    "\n",
    "Size = 224\n",
    "flower_transform = transforms.Compose([transforms.Resize((Size,Size)),\n",
    "                                       transforms.ToTensor(), \n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "flower_dataset = datasets.ImageFolder(root_dir, transform=flower_transform)\n",
    "\n",
    "idx2class = {v: k for k, v in flower_dataset.class_to_idx.items()}\n",
    "\n",
    "print(\"Distribution of classes: \\n\", get_class_distribution(flower_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0459306",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = flower_dataset.targets\n",
    "\n",
    "train_idx, valid_idx= train_test_split(\n",
    "    np.arange(len(targets)), test_size=0.2, random_state=42, shuffle=True, stratify=targets)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(valid_idx)\n",
    "train_loader = DataLoader(dataset=flower_dataset, shuffle=False, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset=flower_dataset, shuffle=False, batch_size=32, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d5036",
   "metadata": {},
   "source": [
    "Let's define configuration of training for wandb sync. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e023a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_BATCHES_TO_LOG = 10\n",
    "config = dict(\n",
    "    epochs=20,\n",
    "    classes=5,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.005,\n",
    "    dataset=\"Flower recognition\",\n",
    "    architecture=\"DenseNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14b53e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1567e",
   "metadata": {},
   "source": [
    "# Split data using splitfolder lib and apply data augmentation on train set (optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2e78d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#splitfolders.ratio(\"../Task/flowers-recognition/flowers\", output=\"flowers_\",\n",
    "#    seed=1337, ratio=(.8, .2), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f2c3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for dataset\n",
    "batch_size = 32\n",
    "valid_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da41d76",
   "metadata": {},
   "source": [
    "# Transformation and augmentation (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d1f44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size = 224\n",
    "#train = \"../Task/flowers_/train\"\n",
    "#val = \"../Task/flowers_/val\"\n",
    "#mean = [0.4363, 0.4328, 0.3291]\n",
    "#std = [0.2129, 0.2075, 0.2038]\n",
    "\n",
    "#train_transforms = transforms.Compose([\n",
    "#    transforms.Resize((Size, Size)),\n",
    " #   transforms.RandomHorizontalFlip(),\n",
    "  #  transforms.RandomRotation(10),\n",
    "   # transforms.ToTensor(),\n",
    "    #transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
    "#])\n",
    "\n",
    "#valid_transforms = transforms.Compose([\n",
    " #   transforms.Resize((Size, Size)),\n",
    "  #  transforms.ToTensor(),\n",
    "   # transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
    "    \n",
    "#])\n",
    "\n",
    "#train_dataset = torchvision.datasets.ImageFolder(root = train, transform = train_transforms)\n",
    "#valid_dataset = torchvision.datasets.ImageFolder(root = val, transform = valid_transforms)\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle =True)\n",
    "#valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = 32, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "788a84c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c968e2",
   "metadata": {},
   "source": [
    "# Vizualization of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf6d66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_batch, label_train = next(iter(train_loader))\n",
    "valid_batch, label_val = next(iter(valid_loader))\n",
    "\n",
    "def showed_transformed_images(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size = 6, shuffle = True)\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "    grid = torchvision.utils.make_grid(images, nrow = 3)\n",
    "    plt.figure(figsize = (11, 11))\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    print('labels: ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "252ffefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_per_class(dataset):\n",
    "    classes = dataset.classes\n",
    "    num_classes = len(dataset.classes)\n",
    "    img_dict = {}\n",
    "    dataset_size = len(dataset)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        img_dict[classes[i]] = 0\n",
    "\n",
    "    for i in range(dataset_size):\n",
    "        img, label = dataset[i]\n",
    "        img_dict[classes[label]] += 1\n",
    "\n",
    "    return img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f3e433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(dataset_obj):\n",
    "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
    "    \n",
    "    for element in dataset_obj:\n",
    "        y_lbl = element[1]\n",
    "        y_lbl = idx2class[y_lbl]\n",
    "        count_dict[y_lbl] += 1\n",
    "            \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "075af3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 611, 'dandelion': 841, 'rose': 627, 'sunflower': 586, 'tulip': 787}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check num of images per class in train set \n",
    "train_images = get_class_distribution(train_dataset)\n",
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d30ae271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 153, 'dandelion': 211, 'rose': 157, 'sunflower': 147, 'tulip': 197}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check num of images per class in test dataset\n",
    "valid_images = get_class_distribution(valid_dataset)\n",
    "valid_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a401bf",
   "metadata": {},
   "source": [
    "# Model selection (transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9543c00",
   "metadata": {},
   "source": [
    "Inception v3 is an image recognition model that has been shown to attain greater than 78.1% accuracy on the ImageNet dataset. The model is the culmination of many ideas developed by multiple researchers over the years. The model itself is made up of symmetric and asymmetric building blocks, including convolutions, average pooling, max pooling, concatenations, dropouts, and fully connected layers. Batch normalization is used extensively throughout the model and applied to activation inputs. Loss is computed using Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e73f8289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): None\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Firstly we will try to train iception Inceptionv3 \n",
    "inception = torchvision.models.inception_v3(pretrained=True, aux_logits=False)\n",
    "for param in inception.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Change the classification layers\n",
    "inception.fc = nn.Linear(in_features=2048, out_features=5, bias=True)\n",
    "inception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24cfb9",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7801fa1",
   "metadata": {},
   "source": [
    "EfficientNet is a convolutional neural network architecture and scaling method that uniformly scales all dimensions of depth/width/resolution using a compound coefficient. Unlike conventional practice that arbitrary scales these factors, the EfficientNet scaling method uniformly scales network width, depth, and resolution with a set of fixed scaling coefficients. It has only 7.8 mln parameters and showed 79.2% Top 1 accuracy on ImageNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3fea983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)\n",
       "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficient_net = torchvision.models.efficientnet_b1(pretrained=True, aux_logits=False)\n",
    "for param in efficient_net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Change the classification layers\n",
    "efficient_net.classifier[1] = nn.Linear(in_features=1280, out_features=5, bias=True)\n",
    "efficient_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb4988c",
   "metadata": {},
   "source": [
    "Since both models show appreciate result in image classification tasks I decided to compare their efficiency in Flowers Recognition task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8ca73",
   "metadata": {},
   "source": [
    "Lets define some helper functions for training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9c8d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters, train_loader, test_loader, model):\n",
    "    with wandb.init(project=\"Provectus_classification_flowers\", config=hyperparameters):\n",
    "        config = wandb.config\n",
    "        model, criterion, optimizer = make(config, model)\n",
    "        print(model)\n",
    "        train(model, train_loader, criterion, optimizer, config)\n",
    "        return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b515b8a",
   "metadata": {},
   "source": [
    "As was shown in EDA notebook dataset is insignificantly imbalanced. For that reason as the main performance metrics \n",
    "I used Matthews correlation coefficient and Cohen Kappa. \n",
    "\n",
    "I train model on 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e82bff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config, model):\n",
    "    # Make the model\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88ff8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, config):\n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Run training and track with wandb\n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    max_acc=0\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        acc = 0.0\n",
    "        print(\"Training....\")\n",
    "        model.train()\n",
    "        matthews_corrcoef = MatthewsCorrCoef(num_classes=5)\n",
    "        f1 = F1Score(num_classes=5)\n",
    "        cohenkappa = CohenKappa(num_classes=5)\n",
    "        for batch_num, (images, labels) in enumerate(loader):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass \n",
    "            outputs = model.forward(images)\n",
    "            op = F.softmax(outputs,dim=1)\n",
    "            final_op = torch.argmax(op,dim=1)\n",
    "            acc += torch.sum(final_op==labels).item()/len(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            precision, recall = precision_recall(outputs, labels, average = 'macro', num_classes = 5)\n",
    "            # Backward pass \n",
    "            loss.backward()\n",
    "            wandb.log({'precision' : precision, 'recall' :recall})\n",
    "            # Step with optimizer\n",
    "            optimizer.step()\n",
    "            train_loss+=(loss.item()/len(images))\n",
    "            if batch_num%50 ==0 and batch_num!=0:\n",
    "                    print(\"TARGET: \",labels)\n",
    "                    print(\"OUTPUT: \",final_op)\n",
    "                    print(\"Accuracy after \",batch_num,\"steps: \",acc/batch_num)\n",
    "                    print('Precision, recall = ', precision, recall)\n",
    "            acc_ = acc/len(train_loader)\n",
    "            train_acc.append(acc)\n",
    "            mat = matthews_corrcoef(outputs, labels)\n",
    "            f1_score = f1(outputs, labels)\n",
    "            ck_train = cohenkappa(outputs, labels)\n",
    "        print(\"Epoch: \",epoch,\"Loss: \",train_loss,\" Accuracy: \",acc, \"Matthews corr.coef: \", mat, \"Cohen Kappa metric on train\", ck_train)\n",
    "        example_ct +=  len(images)\n",
    "        batch_ct += 1\n",
    "\n",
    "        # Report metrics every 50th batch\n",
    "        if ((batch_ct + 1) % 50) == 0:\n",
    "            train_log(loss, example_ct, epoch, acc)\n",
    "            \n",
    "        accuracy_test = 0\n",
    "        eval_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            correct_test = 0\n",
    "            total_test = 0\n",
    "            print(\"Validating.....\")\n",
    "\n",
    "            for batch in valid_loader:\n",
    "                inp,target = batch[0].to(device),batch[1].to(device)\n",
    "                op = F.softmax(inception.forward(inp))\n",
    "                final_op = torch.argmax(op,dim=1)\n",
    "                eval_accuracy += np.sum(final_op.detach().cpu().numpy()==target.detach().cpu().numpy())/len(target)\n",
    "        accuracy_test = (eval_accuracy/len(valid_loader))\n",
    "        print(\"Validation accuracy: \",accuracy_test)\n",
    "        val_acc.append(accuracy_test)\n",
    "            \n",
    "        wandb.log({\"Epochs\" : epoch, \"train_loss\": train_loss, \"Train accuracy\" : train_acc[-1],\n",
    "                   'Validation accuracy' : accuracy_test,\n",
    "                  \"Matthews corr.coef: \": mat, \"F1 score_train: \" : f1_score,\n",
    "                  \"Cohen Kappa\" : ck_train})\n",
    "        torch.onnx.export(model, images, \"model.onnx\")\n",
    "        wandb.save(f\"model_{epoch}.onnx\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5572064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch, accuracy):\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss, 'accuracy' : accuracy}, step=example_ct)\n",
    "    #print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\" + f' accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "330fdc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs=20,\n",
    "    classes=5,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.005,\n",
    "    dataset=\"Flower recognition\",\n",
    "    architecture=\"InceptionV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dae15bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\USER\\Desktop\\Task\\wandb\\run-20220613_011722-3cxir0bw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/artyom9090/Provectus_classification_flowers/runs/3cxir0bw\" target=\"_blank\">bumbling-elevator-1</a></strong> to <a href=\"https://wandb.ai/artyom9090/Provectus_classification_flowers\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): None\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 2, 1, 4, 0, 4, 4, 1, 0, 3, 4, 4, 4, 4, 2, 1, 1, 2, 1, 0, 1, 4, 0, 4,\n",
      "        4, 0, 4, 1, 3, 4, 3, 0])\n",
      "OUTPUT:  tensor([3, 4, 1, 3, 4, 4, 4, 1, 3, 3, 3, 4, 3, 4, 2, 1, 1, 2, 1, 0, 1, 4, 0, 3,\n",
      "        1, 3, 3, 1, 3, 3, 3, 0])\n",
      "Accuracy after  50 steps:  0.57875\n",
      "Precision, recall =  tensor(0.7845) tensor(0.7167)\n",
      "TARGET:  tensor([1, 3, 0, 3, 1, 0, 1, 0, 3, 2, 4, 2, 2, 0, 2, 4, 3, 2, 1, 3, 0, 3, 3, 4,\n",
      "        2, 3, 1, 4, 4, 4, 2, 1])\n",
      "OUTPUT:  tensor([1, 3, 3, 3, 1, 0, 1, 0, 3, 2, 4, 2, 2, 0, 2, 4, 1, 0, 1, 3, 0, 4, 2, 4,\n",
      "        2, 3, 1, 4, 2, 0, 2, 1])\n",
      "Accuracy after  100 steps:  0.6475\n",
      "Precision, recall =  tensor(0.7814) tensor(0.7898)\n",
      "Epoch:  0 Loss:  3.2503461433308467  Accuracy:  69.51339285714286 Matthews corr.coef:  tensor(0.5166) Cohen Kappa metric on train tensor(0.5040)\n",
      "Validating.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4356\\3234579611.py:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  op = F.softmax(inception.forward(inp))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.8080357142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 1/20 [04:06<1:18:01, 246.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([4, 3, 4, 0, 4, 1, 0, 4, 1, 0, 0, 2, 2, 3, 0, 4, 0, 1, 1, 0, 0, 2, 4, 0,\n",
      "        1, 3, 2, 3, 4, 2, 1, 0])\n",
      "OUTPUT:  tensor([4, 1, 1, 0, 4, 1, 1, 1, 1, 0, 2, 2, 2, 3, 3, 3, 1, 1, 1, 0, 0, 2, 4, 3,\n",
      "        1, 2, 2, 3, 2, 2, 1, 0])\n",
      "Accuracy after  50 steps:  0.765625\n",
      "Precision, recall =  tensor(0.7141) tensor(0.6857)\n",
      "TARGET:  tensor([4, 3, 4, 3, 3, 0, 2, 4, 0, 0, 0, 4, 3, 2, 2, 1, 1, 3, 1, 3, 1, 0, 4, 0,\n",
      "        4, 2, 4, 2, 1, 4, 1, 1])\n",
      "OUTPUT:  tensor([4, 3, 4, 3, 3, 1, 3, 4, 0, 4, 1, 2, 4, 1, 4, 4, 1, 4, 1, 1, 1, 0, 3, 0,\n",
      "        4, 2, 4, 4, 1, 4, 1, 1])\n",
      "Accuracy after  100 steps:  0.739375\n",
      "Precision, recall =  tensor(0.6400) tensor(0.5614)\n",
      "Epoch:  1 Loss:  2.5381038639960543  Accuracy:  79.10714285714286 Matthews corr.coef:  tensor(0.8234) Cohen Kappa metric on train tensor(0.8208)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7756696428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 2/20 [08:17<1:14:42, 249.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([4, 0, 0, 1, 3, 3, 4, 1, 2, 3, 1, 4, 1, 0, 3, 3, 4, 0, 0, 4, 0, 3, 1, 0,\n",
      "        3, 2, 1, 0, 2, 2, 4, 1])\n",
      "OUTPUT:  tensor([4, 1, 0, 1, 3, 3, 4, 4, 2, 3, 1, 1, 1, 1, 3, 1, 4, 1, 0, 4, 0, 1, 1, 0,\n",
      "        3, 3, 1, 1, 2, 4, 4, 1])\n",
      "Accuracy after  50 steps:  0.7425\n",
      "Precision, recall =  tensor(0.8018) tensor(0.6810)\n",
      "TARGET:  tensor([0, 1, 1, 1, 4, 4, 4, 2, 0, 4, 1, 1, 0, 3, 0, 4, 1, 0, 1, 1, 2, 4, 1, 0,\n",
      "        3, 2, 2, 3, 2, 1, 4, 2])\n",
      "OUTPUT:  tensor([0, 1, 1, 1, 4, 4, 4, 4, 0, 4, 1, 1, 0, 3, 3, 4, 1, 0, 1, 1, 3, 1, 1, 0,\n",
      "        1, 3, 2, 0, 2, 0, 4, 2])\n",
      "Accuracy after  100 steps:  0.7396875\n",
      "Precision, recall =  tensor(0.7279) tensor(0.6848)\n",
      "Epoch:  2 Loss:  2.6942741608779346  Accuracy:  78.77678571428571 Matthews corr.coef:  tensor(0.6497) Cohen Kappa metric on train tensor(0.6381)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8058035714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|        | 3/20 [12:28<1:10:46, 249.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 0, 0, 1, 1, 1, 0, 3, 3, 3, 2, 4, 4, 3, 2, 4, 0, 3, 3, 3, 3, 1, 2, 1,\n",
      "        4, 3, 1, 2, 3, 1, 0, 2])\n",
      "OUTPUT:  tensor([4, 0, 0, 1, 1, 1, 0, 3, 4, 3, 2, 4, 0, 3, 2, 4, 0, 0, 3, 0, 3, 4, 2, 4,\n",
      "        4, 3, 4, 2, 0, 4, 0, 3])\n",
      "Accuracy after  50 steps:  0.75875\n",
      "Precision, recall =  tensor(0.7492) tensor(0.6890)\n",
      "TARGET:  tensor([1, 3, 2, 4, 3, 0, 4, 4, 0, 1, 4, 2, 2, 4, 4, 3, 2, 2, 2, 0, 2, 2, 3, 4,\n",
      "        4, 3, 2, 1, 4, 1, 1, 3])\n",
      "OUTPUT:  tensor([1, 1, 2, 4, 3, 0, 0, 1, 0, 1, 4, 1, 2, 2, 4, 2, 2, 2, 2, 0, 2, 2, 3, 0,\n",
      "        4, 3, 4, 1, 2, 4, 1, 3])\n",
      "Accuracy after  100 steps:  0.7575\n",
      "Precision, recall =  tensor(0.7076) tensor(0.7378)\n",
      "Epoch:  3 Loss:  2.6403043819591403  Accuracy:  80.70535714285714 Matthews corr.coef:  tensor(0.5667) Cohen Kappa metric on train tensor(0.5513)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7879464285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 4/20 [16:39<1:06:46, 250.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 1, 2, 1, 0, 4, 2, 0, 2, 4, 1, 2, 2, 0, 4, 2, 3, 1, 3, 3, 1, 0, 0, 1,\n",
      "        0, 0, 1, 4, 4, 4, 2, 2])\n",
      "OUTPUT:  tensor([3, 1, 2, 1, 1, 4, 2, 0, 2, 0, 1, 2, 2, 0, 4, 2, 3, 1, 3, 3, 1, 0, 0, 1,\n",
      "        0, 0, 1, 4, 4, 4, 2, 2])\n",
      "Accuracy after  50 steps:  0.773125\n",
      "Precision, recall =  tensor(0.9464) tensor(0.9381)\n",
      "TARGET:  tensor([4, 3, 1, 0, 1, 1, 4, 1, 0, 3, 2, 3, 2, 3, 1, 2, 4, 2, 3, 0, 2, 4, 3, 3,\n",
      "        4, 0, 1, 2, 4, 3, 2, 0])\n",
      "OUTPUT:  tensor([2, 4, 1, 1, 1, 1, 4, 1, 1, 2, 2, 3, 2, 4, 1, 2, 4, 2, 3, 0, 2, 4, 3, 4,\n",
      "        4, 0, 1, 2, 4, 4, 2, 4])\n",
      "Accuracy after  100 steps:  0.7625\n",
      "Precision, recall =  tensor(0.8056) tensor(0.7217)\n",
      "Epoch:  4 Loss:  2.5984322064157044  Accuracy:  81.40178571428571 Matthews corr.coef:  tensor(0.6575) Cohen Kappa metric on train tensor(0.6450)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7991071428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|       | 5/20 [20:49<1:02:35, 250.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([4, 2, 2, 3, 4, 1, 3, 4, 0, 4, 4, 4, 4, 3, 1, 2, 2, 3, 1, 4, 2, 0, 1, 0,\n",
      "        1, 1, 2, 4, 2, 3, 0, 1])\n",
      "OUTPUT:  tensor([1, 2, 2, 3, 4, 1, 4, 4, 0, 4, 4, 4, 2, 4, 1, 2, 2, 3, 1, 4, 2, 0, 1, 0,\n",
      "        1, 1, 1, 4, 2, 3, 0, 1])\n",
      "Accuracy after  50 steps:  0.770625\n",
      "Precision, recall =  tensor(0.8825) tensor(0.8470)\n",
      "TARGET:  tensor([1, 0, 4, 4, 4, 1, 1, 1, 3, 2, 2, 4, 4, 2, 4, 1, 4, 4, 2, 2, 4, 1, 4, 2,\n",
      "        0, 1, 4, 4, 4, 0, 1, 0])\n",
      "OUTPUT:  tensor([1, 0, 0, 4, 4, 1, 1, 1, 3, 2, 2, 4, 3, 2, 4, 1, 2, 3, 4, 2, 4, 1, 3, 2,\n",
      "        0, 3, 4, 2, 3, 0, 1, 0])\n",
      "Accuracy after  100 steps:  0.7575\n",
      "Precision, recall =  tensor(0.7076) tensor(0.8340)\n",
      "Epoch:  5 Loss:  2.873896049335599  Accuracy:  80.80803571428571 Matthews corr.coef:  tensor(0.6465) Cohen Kappa metric on train tensor(0.6304)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8258928571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|       | 6/20 [25:00<58:29, 250.67s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 0, 1, 0, 3, 0, 4, 4, 4, 2, 4, 3, 1, 1, 1, 1, 4, 2, 0, 0, 4, 3, 4, 0,\n",
      "        1, 4, 0, 2, 4, 2, 0, 1])\n",
      "OUTPUT:  tensor([0, 0, 1, 1, 3, 0, 4, 4, 2, 0, 4, 3, 2, 1, 1, 1, 4, 0, 1, 0, 4, 3, 4, 0,\n",
      "        1, 1, 1, 2, 4, 2, 0, 1])\n",
      "Accuracy after  50 steps:  0.7525\n",
      "Precision, recall =  tensor(0.7450) tensor(0.7020)\n",
      "TARGET:  tensor([4, 4, 4, 1, 3, 2, 2, 3, 1, 2, 1, 1, 3, 3, 3, 1, 3, 2, 1, 1, 4, 1, 1, 4,\n",
      "        4, 1, 2, 1, 0, 3, 0, 1])\n",
      "OUTPUT:  tensor([4, 4, 2, 1, 3, 2, 2, 0, 1, 2, 1, 1, 3, 3, 3, 1, 3, 3, 1, 1, 4, 1, 4, 4,\n",
      "        4, 1, 2, 1, 0, 3, 0, 1])\n",
      "Accuracy after  100 steps:  0.7525\n",
      "Precision, recall =  tensor(0.8314) tensor(0.8814)\n",
      "Epoch:  6 Loss:  2.9857260352665826  Accuracy:  80.38392857142857 Matthews corr.coef:  tensor(0.7936) Cohen Kappa metric on train tensor(0.7771)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7879464285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|      | 7/20 [29:12<54:21, 250.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 1, 4, 3, 0, 1, 1, 4, 4, 2, 0, 3, 2, 3, 0, 4, 2, 4, 4, 4, 1, 0, 3, 2,\n",
      "        3, 0, 1, 3, 0, 1, 3, 4])\n",
      "OUTPUT:  tensor([4, 2, 4, 2, 4, 2, 1, 0, 4, 2, 0, 3, 3, 4, 0, 4, 4, 4, 4, 4, 1, 0, 3, 2,\n",
      "        3, 0, 1, 1, 0, 1, 3, 4])\n",
      "Accuracy after  50 steps:  0.763125\n",
      "Precision, recall =  tensor(0.6939) tensor(0.6750)\n",
      "TARGET:  tensor([1, 1, 0, 4, 2, 4, 2, 1, 3, 0, 4, 1, 2, 2, 2, 2, 3, 2, 4, 2, 1, 0, 2, 4,\n",
      "        1, 0, 2, 4, 2, 2, 1, 4])\n",
      "OUTPUT:  tensor([1, 1, 0, 4, 0, 4, 4, 3, 3, 0, 4, 0, 4, 4, 0, 2, 3, 3, 2, 2, 1, 0, 4, 4,\n",
      "        1, 0, 2, 3, 2, 2, 1, 4])\n",
      "Accuracy after  100 steps:  0.7525\n",
      "Precision, recall =  tensor(0.6721) tensor(0.7690)\n",
      "Epoch:  7 Loss:  2.9034084237313698  Accuracy:  80.54017857142857 Matthews corr.coef:  tensor(0.7809) Cohen Kappa metric on train tensor(0.7746)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8180803571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 8/20 [33:23<50:12, 251.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 4, 3, 4, 1, 2, 2, 4, 2, 2, 0, 0, 1, 1, 1, 3, 1, 1, 2, 4, 1, 2, 4, 2,\n",
      "        2, 2, 2, 0, 2, 2, 1, 4])\n",
      "OUTPUT:  tensor([3, 4, 3, 4, 1, 3, 4, 4, 3, 4, 0, 0, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 4, 0,\n",
      "        2, 2, 2, 0, 2, 4, 1, 4])\n",
      "Accuracy after  50 steps:  0.745625\n",
      "Precision, recall =  tensor(0.7728) tensor(0.8667)\n",
      "TARGET:  tensor([2, 1, 4, 4, 0, 1, 2, 3, 0, 1, 1, 2, 3, 2, 4, 2, 2, 4, 4, 2, 1, 0, 0, 1,\n",
      "        4, 1, 0, 0, 3, 3, 2, 2])\n",
      "OUTPUT:  tensor([4, 1, 2, 0, 0, 1, 2, 3, 0, 1, 0, 2, 4, 2, 4, 4, 0, 4, 4, 2, 1, 0, 2, 1,\n",
      "        4, 1, 0, 0, 2, 3, 2, 2])\n",
      "Accuracy after  100 steps:  0.7428125\n",
      "Precision, recall =  tensor(0.7726) tensor(0.7048)\n",
      "Epoch:  8 Loss:  3.224721913092903  Accuracy:  79.69196428571429 Matthews corr.coef:  tensor(0.7332) Cohen Kappa metric on train tensor(0.7273)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8314732142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|     | 9/20 [37:34<45:59, 250.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 2, 0, 4, 3, 3, 1, 0, 1, 1, 0, 2, 0, 1, 4, 4, 0, 3, 1, 2, 2, 3, 1, 0,\n",
      "        0, 2, 3, 3, 1, 1, 3, 1])\n",
      "OUTPUT:  tensor([3, 2, 0, 4, 3, 2, 4, 0, 1, 1, 2, 4, 0, 1, 4, 4, 0, 3, 3, 2, 2, 3, 1, 2,\n",
      "        0, 2, 2, 3, 1, 1, 3, 1])\n",
      "Accuracy after  50 steps:  0.770625\n",
      "Precision, recall =  tensor(0.7914) tensor(0.8084)\n",
      "TARGET:  tensor([0, 3, 0, 4, 3, 4, 1, 1, 2, 2, 0, 2, 2, 4, 1, 4, 4, 4, 4, 1, 3, 0, 2, 3,\n",
      "        4, 2, 1, 2, 1, 3, 0, 1])\n",
      "OUTPUT:  tensor([4, 3, 0, 4, 3, 4, 1, 4, 0, 2, 0, 0, 0, 4, 1, 3, 3, 4, 4, 0, 3, 0, 2, 3,\n",
      "        4, 4, 1, 2, 1, 1, 0, 1])\n",
      "Accuracy after  100 steps:  0.7490625\n",
      "Precision, recall =  tensor(0.7333) tensor(0.6986)\n",
      "Epoch:  9 Loss:  2.936127911188773  Accuracy:  80.53125 Matthews corr.coef:  tensor(0.6869) Cohen Kappa metric on train tensor(0.6813)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8404017857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\wandb\\wandb_torch.py:285: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return tensor.shape == torch.Size([0]) or (~torch.isfinite(tensor)).all().item()\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\wandb\\wandb_torch.py:285: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return tensor.shape == torch.Size([0]) or (~torch.isfinite(tensor)).all().item()\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\wandb\\wandb_torch.py:288: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not torch.isfinite(tensor).all():\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\wandb\\wandb_torch.py:203: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  tmin = flat.min().item()\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\wandb\\wandb_torch.py:204: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  tmax = flat.max().item()\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\wandb\\wandb_torch.py:239: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  {name: wandb.Histogram(np_histogram=(tensor.tolist(), bins.tolist()))},\n",
      " 50%|     | 10/20 [41:46<41:52, 251.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([1, 0, 3, 4, 1, 0, 3, 4, 1, 0, 0, 3, 0, 2, 1, 3, 2, 1, 4, 2, 4, 0, 1, 1,\n",
      "        1, 3, 1, 1, 2, 3, 4, 1])\n",
      "OUTPUT:  tensor([1, 0, 3, 2, 1, 0, 2, 4, 1, 0, 4, 1, 0, 2, 1, 2, 2, 1, 4, 2, 4, 0, 0, 1,\n",
      "        2, 2, 1, 1, 2, 2, 0, 1])\n",
      "Accuracy after  50 steps:  0.77375\n",
      "Precision, recall =  tensor(0.7529) tensor(0.6836)\n",
      "TARGET:  tensor([3, 3, 0, 0, 0, 4, 3, 3, 3, 1, 4, 4, 2, 3, 3, 4, 0, 1, 1, 0, 2, 0, 3, 1,\n",
      "        2, 4, 0, 1, 4, 0, 4, 2])\n",
      "OUTPUT:  tensor([3, 3, 0, 0, 0, 4, 3, 4, 3, 1, 4, 1, 2, 1, 3, 4, 3, 1, 1, 0, 0, 0, 1, 1,\n",
      "        2, 4, 2, 1, 4, 0, 3, 2])\n",
      "Accuracy after  100 steps:  0.74875\n",
      "Precision, recall =  tensor(0.7560) tensor(0.7679)\n",
      "Epoch:  10 Loss:  3.2276358072246825  Accuracy:  80.13392857142857 Matthews corr.coef:  tensor(0.7794) Cohen Kappa metric on train tensor(0.7731)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7845982142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|    | 11/20 [45:57<37:41, 251.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([4, 0, 3, 1, 4, 2, 1, 0, 3, 0, 2, 2, 1, 0, 2, 2, 0, 0, 1, 4, 2, 1, 4, 1,\n",
      "        0, 1, 4, 4, 1, 4, 1, 4])\n",
      "OUTPUT:  tensor([1, 0, 3, 1, 2, 2, 1, 1, 3, 0, 1, 2, 1, 0, 2, 2, 1, 2, 0, 2, 0, 1, 3, 1,\n",
      "        0, 1, 1, 3, 1, 1, 1, 4])\n",
      "Accuracy after  50 steps:  0.773125\n",
      "Precision, recall =  tensor(0.6619) tensor(0.6504)\n",
      "TARGET:  tensor([2, 3, 4, 0, 3, 2, 4, 4, 3, 3, 0, 3, 1, 0, 3, 4, 3, 3, 4, 2, 4, 3, 0, 0,\n",
      "        1, 1, 1, 3, 2, 3, 3, 3])\n",
      "OUTPUT:  tensor([2, 3, 4, 0, 0, 2, 4, 4, 3, 3, 0, 1, 1, 0, 4, 4, 4, 3, 4, 4, 4, 3, 0, 0,\n",
      "        1, 4, 1, 1, 1, 3, 2, 1])\n",
      "Accuracy after  100 steps:  0.754375\n",
      "Precision, recall =  tensor(0.7057) tensor(0.7423)\n",
      "Epoch:  11 Loss:  3.2420840689114163  Accuracy:  80.75 Matthews corr.coef:  tensor(0.7077) Cohen Kappa metric on train tensor(0.6874)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8459821428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 12/20 [50:09<33:31, 251.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([4, 0, 2, 2, 4, 3, 1, 1, 4, 0, 4, 2, 2, 1, 4, 1, 1, 1, 1, 0, 2, 2, 4, 4,\n",
      "        2, 4, 4, 0, 0, 1, 1, 2])\n",
      "OUTPUT:  tensor([4, 0, 1, 2, 4, 3, 1, 1, 4, 0, 2, 2, 3, 1, 4, 1, 1, 1, 3, 0, 3, 1, 4, 4,\n",
      "        2, 4, 4, 0, 0, 1, 1, 2])\n",
      "Accuracy after  50 steps:  0.77125\n",
      "Precision, recall =  tensor(0.7700) tensor(0.8556)\n",
      "TARGET:  tensor([1, 1, 4, 4, 4, 0, 2, 2, 0, 3, 1, 4, 0, 4, 3, 2, 0, 0, 1, 1, 1, 1, 0, 4,\n",
      "        2, 3, 3, 4, 0, 2, 1, 2])\n",
      "OUTPUT:  tensor([1, 1, 0, 4, 4, 4, 0, 2, 0, 3, 1, 4, 0, 4, 3, 2, 0, 4, 1, 1, 1, 1, 0, 4,\n",
      "        2, 3, 0, 4, 0, 4, 4, 4])\n",
      "Accuracy after  100 steps:  0.7603125\n",
      "Precision, recall =  tensor(0.8341) tensor(0.7393)\n",
      "Epoch:  12 Loss:  2.988448100696717  Accuracy:  81.01785714285714 Matthews corr.coef:  tensor(0.8752) Cohen Kappa metric on train tensor(0.8654)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8404017857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|   | 13/20 [54:20<29:19, 251.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([1, 3, 3, 1, 2, 0, 4, 0, 3, 4, 1, 1, 1, 3, 0, 1, 2, 4, 0, 1, 0, 4, 0, 1,\n",
      "        4, 4, 1, 2, 2, 1, 2, 2])\n",
      "OUTPUT:  tensor([1, 4, 3, 1, 2, 0, 4, 0, 1, 4, 0, 1, 1, 3, 0, 1, 2, 4, 0, 1, 0, 4, 2, 1,\n",
      "        2, 4, 1, 2, 2, 0, 1, 2])\n",
      "Accuracy after  50 steps:  0.751875\n",
      "Precision, recall =  tensor(0.8124) tensor(0.7600)\n",
      "TARGET:  tensor([1, 4, 4, 1, 2, 2, 2, 1, 4, 0, 3, 1, 1, 0, 2, 1, 3, 0, 1, 4, 4, 4, 0, 0,\n",
      "        1, 4, 1, 1, 3, 2, 2, 3])\n",
      "OUTPUT:  tensor([1, 4, 4, 1, 2, 2, 4, 1, 2, 4, 4, 1, 1, 0, 4, 1, 3, 0, 4, 4, 4, 3, 0, 1,\n",
      "        2, 4, 1, 1, 3, 4, 4, 3])\n",
      "Accuracy after  100 steps:  0.74625\n",
      "Precision, recall =  tensor(0.7111) tensor(0.6395)\n",
      "Epoch:  13 Loss:  3.379733960410314  Accuracy:  79.82142857142857 Matthews corr.coef:  tensor(0.7841) Cohen Kappa metric on train tensor(0.7753)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8069196428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|   | 14/20 [58:32<25:09, 251.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([0, 4, 2, 3, 1, 4, 1, 0, 3, 3, 3, 3, 1, 2, 3, 1, 4, 2, 1, 1, 1, 0, 3, 1,\n",
      "        4, 4, 4, 1, 4, 4, 1, 0])\n",
      "OUTPUT:  tensor([0, 4, 2, 3, 1, 4, 1, 0, 1, 4, 3, 2, 1, 2, 1, 1, 4, 2, 1, 1, 1, 0, 3, 1,\n",
      "        4, 4, 4, 1, 4, 4, 1, 3])\n",
      "Accuracy after  50 steps:  0.776875\n",
      "Precision, recall =  tensor(0.8444) tensor(0.8357)\n",
      "TARGET:  tensor([3, 1, 2, 0, 2, 1, 1, 4, 4, 1, 0, 4, 0, 1, 3, 1, 1, 3, 2, 4, 4, 3, 3, 3,\n",
      "        4, 1, 4, 1, 3, 4, 0, 0])\n",
      "OUTPUT:  tensor([3, 1, 2, 2, 2, 1, 1, 4, 4, 1, 0, 4, 1, 1, 3, 2, 1, 1, 4, 4, 4, 2, 4, 3,\n",
      "        4, 1, 0, 1, 1, 1, 0, 0])\n",
      "Accuracy after  100 steps:  0.7625\n",
      "Precision, recall =  tensor(0.7133) tensor(0.6668)\n",
      "Epoch:  14 Loss:  3.1174229962219084  Accuracy:  81.22767857142857 Matthews corr.coef:  tensor(0.7787) Cohen Kappa metric on train tensor(0.7724)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8348214285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|  | 15/20 [1:02:43<20:57, 251.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 4, 2, 3, 1, 1, 4, 1, 1, 4, 0, 1, 3, 2, 3, 0, 4, 2, 0, 2, 0, 1, 0, 1,\n",
      "        1, 0, 4, 2, 0, 0, 4, 1])\n",
      "OUTPUT:  tensor([2, 0, 2, 3, 4, 1, 4, 1, 4, 4, 0, 1, 3, 2, 4, 1, 3, 2, 4, 2, 0, 1, 0, 1,\n",
      "        1, 0, 4, 2, 0, 2, 2, 1])\n",
      "Accuracy after  50 steps:  0.77625\n",
      "Precision, recall =  tensor(0.7107) tensor(0.7139)\n",
      "TARGET:  tensor([3, 3, 3, 4, 1, 3, 4, 3, 2, 3, 0, 3, 4, 4, 2, 4, 4, 2, 2, 0, 4, 3, 4, 1,\n",
      "        2, 4, 3, 3, 1, 0, 0, 0])\n",
      "OUTPUT:  tensor([3, 1, 4, 4, 1, 4, 4, 3, 2, 3, 2, 3, 4, 4, 4, 4, 4, 2, 2, 0, 4, 0, 4, 1,\n",
      "        4, 1, 3, 0, 1, 0, 0, 0])\n",
      "Accuracy after  100 steps:  0.75875\n",
      "Precision, recall =  tensor(0.7367) tensor(0.7578)\n",
      "Epoch:  15 Loss:  3.128047803150756  Accuracy:  80.71428571428571 Matthews corr.coef:  tensor(0.6194) Cohen Kappa metric on train tensor(0.6118)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8337053571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 16/20 [1:06:55<16:45, 251.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([1, 0, 0, 3, 1, 3, 4, 0, 1, 1, 0, 3, 2, 4, 4, 2, 1, 0, 0, 2, 4, 3, 1, 3,\n",
      "        4, 0, 3, 4, 4, 4, 0, 2])\n",
      "OUTPUT:  tensor([1, 0, 0, 3, 1, 1, 1, 0, 0, 1, 0, 3, 0, 4, 4, 0, 3, 0, 1, 2, 4, 3, 1, 3,\n",
      "        4, 0, 1, 2, 4, 4, 0, 2])\n",
      "Accuracy after  50 steps:  0.789375\n",
      "Precision, recall =  tensor(0.7333) tensor(0.6917)\n",
      "TARGET:  tensor([3, 0, 0, 3, 3, 4, 1, 0, 3, 2, 1, 3, 2, 4, 4, 3, 2, 1, 0, 2, 4, 2, 0, 4,\n",
      "        1, 0, 1, 0, 3, 0, 0, 4])\n",
      "OUTPUT:  tensor([3, 0, 0, 3, 4, 4, 0, 0, 3, 2, 1, 4, 2, 4, 4, 3, 2, 1, 0, 4, 4, 2, 1, 4,\n",
      "        0, 0, 1, 0, 2, 0, 0, 4])\n",
      "Accuracy after  100 steps:  0.7734375\n",
      "Precision, recall =  tensor(0.8033) tensor(0.7721)\n",
      "Epoch:  16 Loss:  3.0573365752186095  Accuracy:  82.49107142857143 Matthews corr.coef:  tensor(0.5901) Cohen Kappa metric on train tensor(0.5772)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8169642857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%| | 17/20 [1:11:06<12:34, 251.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 3, 3, 2, 4, 4, 2, 0, 3, 4, 4, 1, 0, 2, 4, 1, 2, 4, 2, 0, 1, 0, 0, 4,\n",
      "        2, 3, 0, 2, 0, 0, 1, 1])\n",
      "OUTPUT:  tensor([2, 3, 3, 2, 3, 4, 2, 0, 3, 2, 4, 1, 0, 3, 4, 1, 2, 4, 2, 0, 1, 0, 0, 3,\n",
      "        3, 3, 0, 2, 1, 0, 1, 0])\n",
      "Accuracy after  50 steps:  0.738125\n",
      "Precision, recall =  tensor(0.8064) tensor(0.7993)\n",
      "TARGET:  tensor([3, 1, 4, 3, 3, 1, 0, 2, 0, 0, 4, 1, 2, 4, 2, 4, 1, 3, 1, 4, 1, 1, 1, 0,\n",
      "        1, 0, 0, 3, 2, 1, 1, 3])\n",
      "OUTPUT:  tensor([3, 1, 4, 3, 4, 1, 0, 2, 0, 0, 4, 0, 3, 0, 4, 4, 1, 3, 1, 2, 1, 1, 0, 0,\n",
      "        1, 4, 0, 4, 2, 1, 1, 3])\n",
      "Accuracy after  100 steps:  0.75\n",
      "Precision, recall =  tensor(0.7040) tensor(0.6836)\n",
      "Epoch:  17 Loss:  3.354505668926452  Accuracy:  79.94642857142857 Matthews corr.coef:  tensor(0.7855) Cohen Kappa metric on train tensor(0.7727)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8348214285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%| | 18/20 [1:15:17<08:22, 251.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 1, 1, 4, 2, 4, 2, 1, 2, 0, 1, 1, 3, 4, 0, 4, 1, 3, 1, 2, 1, 4, 3, 4,\n",
      "        4, 4, 2, 0, 1, 1, 1, 1])\n",
      "OUTPUT:  tensor([2, 1, 2, 2, 2, 4, 2, 1, 2, 0, 1, 1, 3, 4, 0, 4, 4, 0, 0, 2, 1, 4, 3, 4,\n",
      "        4, 4, 3, 0, 0, 1, 4, 1])\n",
      "Accuracy after  50 steps:  0.77375\n",
      "Precision, recall =  tensor(0.7317) tensor(0.7917)\n",
      "TARGET:  tensor([2, 1, 0, 4, 2, 0, 0, 2, 4, 0, 2, 3, 3, 1, 0, 2, 2, 1, 0, 2, 0, 4, 1, 3,\n",
      "        0, 4, 1, 3, 4, 1, 1, 3])\n",
      "OUTPUT:  tensor([3, 3, 0, 4, 2, 3, 1, 2, 4, 2, 1, 3, 3, 1, 0, 0, 4, 4, 0, 2, 0, 4, 1, 3,\n",
      "        0, 4, 1, 3, 2, 1, 1, 3])\n",
      "Accuracy after  100 steps:  0.775\n",
      "Precision, recall =  tensor(0.6879) tensor(0.7136)\n",
      "Epoch:  18 Loss:  2.9973019464606687  Accuracy:  82.42410714285714 Matthews corr.coef:  tensor(0.5345) Cohen Kappa metric on train tensor(0.5164)\n",
      "Validating.....\n",
      "Validation accuracy:  0.8470982142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|| 19/20 [1:19:29<04:11, 251.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 0, 0, 0, 2, 4, 4, 4, 4, 4, 0, 1, 4, 1, 0, 0, 2, 0, 3, 4, 1, 3, 1, 4,\n",
      "        0, 4, 2, 2, 3, 0, 3, 1])\n",
      "OUTPUT:  tensor([2, 0, 0, 3, 3, 4, 4, 4, 3, 1, 0, 1, 4, 1, 0, 0, 2, 0, 3, 4, 1, 3, 1, 4,\n",
      "        0, 2, 2, 2, 3, 0, 3, 1])\n",
      "Accuracy after  50 steps:  0.783125\n",
      "Precision, recall =  tensor(0.8410) tensor(0.8711)\n",
      "TARGET:  tensor([1, 3, 4, 2, 2, 4, 0, 2, 1, 3, 0, 1, 0, 4, 1, 0, 1, 1, 4, 3, 3, 4, 2, 2,\n",
      "        1, 0, 3, 4, 3, 3, 4, 1])\n",
      "OUTPUT:  tensor([1, 3, 4, 2, 2, 4, 1, 2, 3, 1, 0, 1, 2, 3, 1, 0, 1, 1, 2, 3, 3, 4, 4, 2,\n",
      "        1, 3, 3, 4, 2, 3, 4, 1])\n",
      "Accuracy after  100 steps:  0.76625\n",
      "Precision, recall =  tensor(0.7615) tensor(0.7007)\n",
      "Epoch:  19 Loss:  3.1056488962577924  Accuracy:  81.79017857142857 Matthews corr.coef:  tensor(0.4596) Cohen Kappa metric on train tensor(0.4483)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [1:23:41<00:00, 251.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cohen Kappa</td><td></td></tr><tr><td>Epochs</td><td></td></tr><tr><td>F1 score_train: </td><td></td></tr><tr><td>Matthews corr.coef: </td><td></td></tr><tr><td>Train accuracy</td><td></td></tr><tr><td>Validation accuracy</td><td></td></tr><tr><td>precision</td><td></td></tr><tr><td>recall</td><td></td></tr><tr><td>train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cohen Kappa</td><td>0.44828</td></tr><tr><td>Epochs</td><td>19</td></tr><tr><td>F1 score_train: </td><td>0.57143</td></tr><tr><td>Matthews corr.coef: </td><td>0.4596</td></tr><tr><td>Train accuracy</td><td>81.79018</td></tr><tr><td>Validation accuracy</td><td>0.82812</td></tr><tr><td>precision</td><td>0.60635</td></tr><tr><td>recall</td><td>0.53833</td></tr><tr><td>train_loss</td><td>3.10565</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bumbling-elevator-1</strong>: <a href=\"https://wandb.ai/artyom9090/Provectus_classification_flowers/runs/3cxir0bw\" target=\"_blank\">https://wandb.ai/artyom9090/Provectus_classification_flowers/runs/3cxir0bw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220613_011722-3cxir0bw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_incp = model_pipeline(config, train_loader, valid_loader, inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed330eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs=20,\n",
    "    classes=5,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.005,\n",
    "    dataset=\"Flower recognition\",\n",
    "    architecture=\"EfficientNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9197db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\USER\\Desktop\\Task\\wandb\\run-20220613_024116-27f17avm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/artyom9090/Provectus_classification_flowers/runs/27f17avm\" target=\"_blank\">wandering-sun-2</a></strong> to <a href=\"https://wandb.ai/artyom9090/Provectus_classification_flowers\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): ConvNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)\n",
      "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): ConvNormActivation(\n",
      "            (0): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (8): ConvNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=True)\n",
      "    (1): Linear(in_features=1280, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 4, 1, 1, 2, 4, 0, 0, 4, 0, 0, 2, 3, 0, 4, 2, 1, 4, 0, 3, 1, 1, 1, 0,\n",
      "        4, 0, 4, 0, 2, 2, 2, 0])\n",
      "OUTPUT:  tensor([3, 4, 1, 1, 2, 3, 0, 1, 4, 3, 0, 2, 3, 1, 4, 2, 1, 3, 0, 3, 1, 1, 1, 0,\n",
      "        4, 0, 4, 0, 2, 2, 1, 1])\n",
      "Accuracy after  50 steps:  0.750625\n",
      "Precision, recall =  tensor(0.8200) tensor(0.8295)\n",
      "TARGET:  tensor([1, 3, 1, 2, 0, 4, 0, 2, 2, 0, 1, 1, 1, 4, 4, 4, 4, 2, 1, 1, 1, 1, 2, 1,\n",
      "        3, 4, 0, 4, 4, 4, 0, 1])\n",
      "OUTPUT:  tensor([1, 3, 1, 2, 3, 4, 3, 2, 3, 0, 1, 1, 1, 0, 4, 4, 4, 2, 1, 1, 3, 1, 2, 1,\n",
      "        3, 4, 0, 0, 4, 2, 0, 1])\n",
      "Accuracy after  100 steps:  0.7828125\n",
      "Precision, recall =  tensor(0.7467) tensor(0.7952)\n",
      "Epoch:  0 Loss:  2.0232686568051577  Accuracy:  84.01785714285714 Matthews corr.coef:  tensor(0.8696) Cohen Kappa metric on train tensor(0.8623)\n",
      "Validating.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4356\\3234579611.py:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  op = F.softmax(inception.forward(inp))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 1/20 [05:31<1:44:50, 331.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([1, 0, 0, 3, 4, 1, 3, 4, 0, 4, 1, 4, 1, 0, 3, 2, 2, 2, 2, 3, 0, 3, 4, 3,\n",
      "        2, 2, 3, 0, 1, 2, 1, 2])\n",
      "OUTPUT:  tensor([1, 0, 0, 3, 4, 1, 3, 4, 0, 4, 1, 3, 2, 0, 3, 2, 0, 2, 2, 1, 0, 3, 4, 3,\n",
      "        2, 4, 3, 0, 1, 2, 1, 2])\n",
      "Accuracy after  50 steps:  0.873125\n",
      "Precision, recall =  tensor(0.8410) tensor(0.8481)\n",
      "TARGET:  tensor([1, 4, 1, 0, 4, 4, 1, 0, 0, 0, 4, 1, 2, 0, 4, 2, 1, 0, 3, 2, 1, 4, 2, 4,\n",
      "        0, 1, 2, 4, 1, 4, 1, 3])\n",
      "OUTPUT:  tensor([1, 4, 1, 2, 3, 4, 1, 0, 0, 0, 4, 1, 2, 0, 4, 2, 1, 0, 3, 2, 1, 4, 2, 4,\n",
      "        0, 3, 2, 4, 1, 4, 1, 3])\n",
      "Accuracy after  100 steps:  0.8571875\n",
      "Precision, recall =  tensor(0.8667) tensor(0.9270)\n",
      "Epoch:  1 Loss:  1.4487339028356863  Accuracy:  91.63392857142857 Matthews corr.coef:  tensor(0.7830) Cohen Kappa metric on train tensor(0.7767)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 2/20 [11:00<1:39:06, 330.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([4, 2, 4, 3, 3, 3, 4, 4, 4, 1, 3, 1, 4, 4, 4, 2, 0, 4, 2, 1, 4, 1, 1, 0,\n",
      "        4, 1, 3, 2, 2, 2, 1, 2])\n",
      "OUTPUT:  tensor([4, 2, 2, 3, 3, 3, 4, 3, 4, 0, 3, 1, 3, 4, 0, 4, 0, 4, 2, 1, 4, 1, 1, 0,\n",
      "        4, 1, 3, 2, 3, 3, 3, 2])\n",
      "Accuracy after  50 steps:  0.883125\n",
      "Precision, recall =  tensor(0.7350) tensor(0.7844)\n",
      "TARGET:  tensor([1, 1, 1, 3, 1, 1, 2, 4, 2, 2, 4, 0, 2, 2, 4, 4, 1, 0, 4, 3, 1, 3, 4, 1,\n",
      "        2, 1, 1, 1, 3, 1, 2, 4])\n",
      "OUTPUT:  tensor([1, 1, 0, 3, 1, 0, 2, 4, 2, 3, 4, 0, 2, 2, 4, 2, 1, 0, 2, 3, 1, 0, 4, 1,\n",
      "        3, 4, 1, 1, 3, 1, 2, 4])\n",
      "Accuracy after  100 steps:  0.86875\n",
      "Precision, recall =  tensor(0.7095) tensor(0.7857)\n",
      "Epoch:  2 Loss:  1.3491218288296036  Accuracy:  92.65178571428571 Matthews corr.coef:  tensor(0.6524) Cohen Kappa metric on train tensor(0.6387)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7935267857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|        | 3/20 [16:30<1:33:28, 329.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 3, 2, 2, 0, 0, 2, 1, 4, 4, 4, 4, 2, 3, 3, 4, 3, 4, 2, 1, 1, 2, 1, 1,\n",
      "        2, 3, 0, 4, 4, 1, 2, 4])\n",
      "OUTPUT:  tensor([0, 3, 2, 2, 0, 0, 2, 1, 4, 4, 2, 4, 4, 3, 3, 4, 3, 4, 2, 0, 1, 4, 1, 1,\n",
      "        0, 3, 0, 4, 4, 1, 2, 0])\n",
      "Accuracy after  50 steps:  0.8725\n",
      "Precision, recall =  tensor(0.8079) tensor(0.8333)\n",
      "TARGET:  tensor([2, 4, 0, 2, 4, 4, 2, 3, 0, 4, 2, 3, 0, 3, 1, 1, 2, 2, 3, 2, 4, 3, 1, 3,\n",
      "        0, 2, 0, 0, 1, 4, 4, 0])\n",
      "OUTPUT:  tensor([2, 4, 0, 4, 4, 4, 2, 3, 0, 2, 2, 3, 0, 3, 1, 1, 2, 2, 4, 2, 4, 3, 1, 1,\n",
      "        0, 2, 0, 0, 1, 1, 0, 0])\n",
      "Accuracy after  100 steps:  0.8603125\n",
      "Precision, recall =  tensor(0.8167) tensor(0.8226)\n",
      "Epoch:  3 Loss:  1.375260735662388  Accuracy:  91.85714285714286 Matthews corr.coef:  tensor(0.8198) Cohen Kappa metric on train tensor(0.8185)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 4/20 [21:59<1:27:56, 329.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([0, 2, 4, 1, 4, 3, 0, 1, 2, 1, 3, 1, 3, 2, 1, 3, 3, 4, 1, 1, 4, 3, 0, 3,\n",
      "        4, 4, 1, 1, 4, 2, 4, 0])\n",
      "OUTPUT:  tensor([0, 2, 4, 1, 4, 3, 0, 1, 2, 1, 3, 1, 3, 2, 1, 3, 3, 2, 0, 3, 4, 3, 0, 3,\n",
      "        2, 2, 2, 1, 4, 2, 4, 0])\n",
      "Accuracy after  50 steps:  0.888125\n",
      "Precision, recall =  tensor(0.8350) tensor(0.8583)\n",
      "TARGET:  tensor([1, 0, 0, 4, 0, 3, 4, 2, 2, 3, 0, 0, 0, 4, 2, 4, 4, 2, 3, 0, 1, 4, 3, 1,\n",
      "        0, 0, 4, 4, 2, 3, 4, 1])\n",
      "OUTPUT:  tensor([1, 0, 0, 1, 4, 3, 4, 2, 2, 3, 0, 0, 0, 4, 2, 3, 4, 4, 3, 0, 1, 4, 3, 1,\n",
      "        3, 0, 4, 4, 2, 3, 4, 1])\n",
      "Accuracy after  100 steps:  0.8746875\n",
      "Precision, recall =  tensor(0.8584) tensor(0.8711)\n",
      "Epoch:  4 Loss:  1.3284806845809467  Accuracy:  92.87946428571429 Matthews corr.coef:  tensor(0.7484) Cohen Kappa metric on train tensor(0.7329)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|       | 5/20 [27:29<1:22:24, 329.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([0, 3, 1, 3, 2, 1, 1, 4, 3, 3, 0, 4, 1, 2, 1, 3, 3, 1, 0, 4, 0, 2, 3, 2,\n",
      "        4, 0, 1, 4, 2, 2, 1, 3])\n",
      "OUTPUT:  tensor([0, 3, 1, 3, 2, 1, 1, 4, 3, 3, 0, 4, 1, 2, 1, 3, 3, 1, 0, 4, 0, 2, 3, 2,\n",
      "        4, 0, 1, 4, 2, 2, 1, 3])\n",
      "Accuracy after  50 steps:  0.878125\n",
      "Precision, recall =  tensor(1.) tensor(1.)\n",
      "TARGET:  tensor([1, 0, 1, 3, 1, 1, 4, 0, 1, 4, 0, 1, 1, 0, 3, 4, 1, 4, 0, 4, 0, 2, 2, 4,\n",
      "        4, 1, 1, 4, 2, 4, 2, 4])\n",
      "OUTPUT:  tensor([1, 0, 1, 3, 1, 1, 4, 0, 1, 3, 4, 1, 1, 0, 3, 4, 1, 4, 0, 4, 0, 2, 2, 2,\n",
      "        4, 1, 1, 4, 2, 4, 2, 4])\n",
      "Accuracy after  100 steps:  0.8659375\n",
      "Precision, recall =  tensor(0.8711) tensor(0.9267)\n",
      "Epoch:  5 Loss:  1.3501678416838072  Accuracy:  92.61160714285714 Matthews corr.coef:  tensor(0.8702) Cohen Kappa metric on train tensor(0.8600)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7935267857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|       | 6/20 [32:59<1:16:57, 329.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([0, 0, 1, 2, 1, 0, 3, 0, 4, 4, 4, 1, 4, 0, 2, 1, 1, 1, 2, 1, 4, 3, 3, 4,\n",
      "        1, 4, 0, 3, 2, 4, 0, 2])\n",
      "OUTPUT:  tensor([0, 0, 1, 2, 1, 0, 3, 3, 4, 3, 1, 1, 4, 2, 2, 1, 1, 1, 4, 1, 4, 3, 3, 4,\n",
      "        1, 4, 0, 3, 2, 4, 0, 2])\n",
      "Accuracy after  50 steps:  0.90125\n",
      "Precision, recall =  tensor(0.8425) tensor(0.8529)\n",
      "TARGET:  tensor([4, 4, 1, 0, 1, 3, 1, 2, 3, 0, 0, 4, 0, 4, 4, 4, 4, 0, 4, 1, 4, 4, 4, 1,\n",
      "        1, 1, 1, 4, 1, 0, 1, 3])\n",
      "OUTPUT:  tensor([4, 4, 1, 0, 1, 3, 0, 2, 3, 0, 0, 4, 0, 4, 4, 4, 4, 1, 4, 2, 2, 2, 4, 1,\n",
      "        1, 1, 1, 2, 1, 0, 1, 3])\n",
      "Accuracy after  100 steps:  0.8878125\n",
      "Precision, recall =  tensor(0.7844) tensor(0.8767)\n",
      "Epoch:  6 Loss:  1.2202779469412885  Accuracy:  94.98660714285714 Matthews corr.coef:  tensor(0.8667) Cohen Kappa metric on train tensor(0.8639)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|      | 7/20 [38:30<1:11:31, 330.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([1, 4, 4, 3, 4, 0, 1, 0, 3, 4, 0, 1, 1, 2, 1, 0, 2, 1, 4, 3, 1, 2, 3, 2,\n",
      "        4, 3, 3, 4, 4, 2, 3, 0])\n",
      "OUTPUT:  tensor([1, 4, 4, 3, 4, 0, 4, 2, 3, 4, 0, 1, 1, 2, 1, 0, 2, 1, 4, 2, 1, 2, 0, 2,\n",
      "        4, 3, 3, 4, 4, 2, 3, 0])\n",
      "Accuracy after  50 steps:  0.90375\n",
      "Precision, recall =  tensor(0.8806) tensor(0.8743)\n",
      "TARGET:  tensor([4, 4, 1, 0, 1, 1, 1, 1, 2, 4, 1, 3, 4, 1, 4, 1, 0, 4, 1, 0, 4, 3, 2, 1,\n",
      "        4, 3, 3, 4, 1, 0, 2, 1])\n",
      "OUTPUT:  tensor([4, 4, 1, 0, 1, 1, 1, 1, 2, 4, 3, 1, 4, 1, 4, 1, 0, 2, 1, 0, 2, 3, 4, 1,\n",
      "        4, 3, 3, 4, 1, 0, 2, 1])\n",
      "Accuracy after  100 steps:  0.8915625\n",
      "Precision, recall =  tensor(0.8083) tensor(0.8222)\n",
      "Epoch:  7 Loss:  1.1306075262171882  Accuracy:  95.49107142857143 Matthews corr.coef:  tensor(0.9134) Cohen Kappa metric on train tensor(0.9089)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7935267857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 8/20 [43:59<1:05:59, 329.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 2, 0, 1, 4, 4, 1, 1, 4, 0, 4, 1, 0, 4, 3, 1, 4, 1, 2, 0, 3, 0, 2, 3,\n",
      "        1, 3, 3, 4, 4, 4, 2, 1])\n",
      "OUTPUT:  tensor([2, 0, 0, 1, 4, 4, 1, 1, 4, 0, 4, 1, 0, 4, 3, 1, 4, 1, 2, 4, 3, 0, 2, 3,\n",
      "        1, 3, 0, 4, 4, 4, 4, 1])\n",
      "Accuracy after  50 steps:  0.891875\n",
      "Precision, recall =  tensor(0.8970) tensor(0.8400)\n",
      "TARGET:  tensor([1, 3, 1, 1, 1, 2, 2, 0, 4, 3, 2, 4, 4, 1, 4, 1, 0, 3, 4, 0, 3, 4, 2, 2,\n",
      "        1, 0, 1, 0, 1, 4, 1, 1])\n",
      "OUTPUT:  tensor([1, 3, 1, 0, 1, 2, 2, 0, 4, 3, 2, 1, 4, 1, 4, 1, 0, 3, 4, 0, 3, 4, 0, 2,\n",
      "        1, 0, 0, 0, 1, 4, 1, 1])\n",
      "Accuracy after  100 steps:  0.879375\n",
      "Precision, recall =  tensor(0.9050) tensor(0.8951)\n",
      "Epoch:  8 Loss:  1.2881986725343657  Accuracy:  94.10267857142857 Matthews corr.coef:  tensor(0.7697) Cohen Kappa metric on train tensor(0.7643)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|     | 9/20 [49:29<1:00:28, 329.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 1, 4, 2, 1, 2, 1, 3, 3, 0, 0, 1, 3, 4, 4, 4, 4, 3, 0, 4, 2, 1, 2, 4,\n",
      "        1, 0, 4, 1, 0, 0, 2, 0])\n",
      "OUTPUT:  tensor([3, 1, 4, 2, 1, 2, 1, 3, 3, 0, 0, 1, 3, 4, 4, 4, 4, 3, 1, 4, 2, 0, 2, 4,\n",
      "        1, 0, 4, 1, 1, 0, 2, 1])\n",
      "Accuracy after  50 steps:  0.885\n",
      "Precision, recall =  tensor(0.8933) tensor(0.8857)\n",
      "TARGET:  tensor([0, 2, 0, 2, 0, 4, 3, 2, 1, 0, 2, 4, 2, 3, 2, 3, 2, 1, 4, 4, 2, 4, 4, 2,\n",
      "        2, 3, 4, 0, 0, 2, 0, 2])\n",
      "OUTPUT:  tensor([0, 2, 4, 4, 0, 4, 1, 3, 1, 0, 2, 4, 2, 3, 2, 3, 2, 1, 4, 4, 2, 4, 4, 3,\n",
      "        2, 3, 4, 0, 0, 2, 0, 2])\n",
      "Accuracy after  100 steps:  0.8753125\n",
      "Precision, recall =  tensor(0.8089) tensor(0.8714)\n",
      "Epoch:  9 Loss:  1.3481008573767863  Accuracy:  93.70535714285714 Matthews corr.coef:  tensor(0.8636) Cohen Kappa metric on train tensor(0.8607)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|     | 10/20 [55:00<55:01, 330.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([1, 1, 2, 3, 2, 2, 3, 2, 0, 3, 2, 2, 4, 3, 0, 0, 2, 3, 1, 1, 3, 2, 0, 2,\n",
      "        1, 3, 3, 0, 0, 4, 2, 3])\n",
      "OUTPUT:  tensor([1, 1, 2, 3, 2, 2, 3, 4, 0, 1, 2, 2, 4, 3, 0, 0, 2, 3, 1, 1, 3, 2, 0, 2,\n",
      "        1, 3, 3, 0, 0, 4, 2, 4])\n",
      "Accuracy after  50 steps:  0.898125\n",
      "Precision, recall =  tensor(0.8667) tensor(0.9356)\n",
      "TARGET:  tensor([4, 1, 4, 1, 0, 0, 1, 4, 4, 1, 1, 4, 2, 1, 3, 0, 4, 2, 1, 4, 2, 2, 4, 1,\n",
      "        4, 0, 3, 3, 3, 1, 1, 3])\n",
      "OUTPUT:  tensor([4, 1, 4, 1, 0, 4, 1, 4, 4, 1, 1, 4, 2, 1, 3, 0, 4, 2, 1, 4, 2, 1, 4, 4,\n",
      "        4, 0, 3, 3, 3, 1, 1, 3])\n",
      "Accuracy after  100 steps:  0.88375\n",
      "Precision, recall =  tensor(0.9436) tensor(0.8800)\n",
      "Epoch:  10 Loss:  1.2088989286816545  Accuracy:  94.41517857142857 Matthews corr.coef:  tensor(0.7769) Cohen Kappa metric on train tensor(0.7705)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|    | 11/20 [1:00:32<49:38, 330.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 4, 0, 2, 4, 1, 0, 1, 2, 3, 1, 4, 4, 1, 3, 1, 4, 4, 4, 4, 2, 2, 1, 1,\n",
      "        4, 2, 0, 3, 2, 2, 1, 3])\n",
      "OUTPUT:  tensor([2, 4, 0, 2, 4, 1, 0, 1, 2, 3, 1, 1, 4, 1, 3, 1, 4, 4, 4, 4, 2, 2, 1, 0,\n",
      "        3, 2, 0, 3, 2, 2, 1, 3])\n",
      "Accuracy after  50 steps:  0.90875\n",
      "Precision, recall =  tensor(0.8850) tensor(0.9306)\n",
      "TARGET:  tensor([0, 3, 3, 0, 2, 1, 2, 3, 4, 1, 0, 3, 4, 4, 0, 0, 2, 1, 1, 2, 2, 4, 0, 4,\n",
      "        4, 1, 2, 3, 4, 0, 4, 1])\n",
      "OUTPUT:  tensor([3, 3, 3, 0, 2, 1, 2, 4, 0, 1, 0, 0, 4, 4, 0, 0, 2, 1, 1, 2, 2, 4, 0, 4,\n",
      "        4, 1, 2, 4, 4, 0, 4, 1])\n",
      "Accuracy after  100 steps:  0.893125\n",
      "Precision, recall =  tensor(0.8389) tensor(0.8264)\n",
      "Epoch:  11 Loss:  1.1995738966257445  Accuracy:  95.40178571428571 Matthews corr.coef:  tensor(0.9565) Cohen Kappa metric on train tensor(0.9550)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 12/20 [1:06:04<44:08, 331.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([0, 3, 2, 1, 1, 0, 1, 4, 4, 1, 4, 4, 4, 4, 2, 4, 2, 1, 3, 1, 2, 0, 4, 2,\n",
      "        4, 1, 0, 3, 3, 4, 1, 0])\n",
      "OUTPUT:  tensor([0, 3, 2, 1, 1, 0, 3, 4, 0, 3, 4, 4, 4, 4, 2, 4, 4, 1, 3, 1, 2, 0, 4, 2,\n",
      "        4, 1, 0, 3, 3, 2, 1, 0])\n",
      "Accuracy after  50 steps:  0.9025\n",
      "Precision, recall =  tensor(0.8378) tensor(0.8700)\n",
      "TARGET:  tensor([3, 2, 1, 1, 4, 3, 2, 4, 3, 1, 3, 0, 4, 3, 3, 0, 4, 0, 0, 1, 4, 2, 3, 0,\n",
      "        0, 1, 4, 3, 1, 4, 1, 4])\n",
      "OUTPUT:  tensor([3, 2, 1, 1, 4, 1, 4, 4, 3, 1, 3, 0, 4, 3, 3, 0, 4, 0, 0, 3, 4, 4, 2, 0,\n",
      "        0, 1, 4, 3, 1, 4, 1, 4])\n",
      "Accuracy after  100 steps:  0.8853125\n",
      "Precision, recall =  tensor(0.8029) tensor(0.7881)\n",
      "Epoch:  12 Loss:  1.2134234675405813  Accuracy:  94.61160714285714 Matthews corr.coef:  tensor(0.8663) Cohen Kappa metric on train tensor(0.8650)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|   | 13/20 [1:11:35<38:37, 331.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 1, 1, 4, 1, 3, 0, 3, 4, 4, 4, 0, 4, 2, 2, 2, 4, 2, 2, 4, 0, 3, 2, 1,\n",
      "        2, 1, 4, 4, 1, 1, 1, 2])\n",
      "OUTPUT:  tensor([3, 1, 1, 4, 1, 3, 0, 3, 2, 4, 1, 0, 4, 2, 2, 2, 4, 2, 2, 4, 0, 3, 2, 1,\n",
      "        2, 0, 4, 4, 1, 1, 1, 2])\n",
      "Accuracy after  50 steps:  0.893125\n",
      "Precision, recall =  tensor(0.9028) tensor(0.9306)\n",
      "TARGET:  tensor([3, 1, 1, 3, 3, 2, 1, 2, 3, 0, 3, 0, 2, 2, 3, 0, 4, 4, 3, 4, 1, 3, 0, 4,\n",
      "        4, 2, 4, 4, 2, 4, 2, 2])\n",
      "OUTPUT:  tensor([1, 1, 1, 3, 3, 2, 1, 4, 0, 0, 3, 0, 2, 2, 3, 0, 4, 4, 3, 4, 1, 3, 0, 4,\n",
      "        4, 2, 4, 4, 2, 4, 2, 2])\n",
      "Accuracy after  100 steps:  0.88875\n",
      "Precision, recall =  tensor(0.8978) tensor(0.9250)\n",
      "Epoch:  13 Loss:  1.187923840513187  Accuracy:  94.90178571428571 Matthews corr.coef:  tensor(0.9552) Cohen Kappa metric on train tensor(0.9536)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|   | 14/20 [1:17:06<33:05, 331.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([2, 3, 4, 4, 3, 2, 1, 2, 1, 3, 1, 4, 0, 2, 1, 4, 4, 0, 0, 4, 4, 1, 3, 1,\n",
      "        2, 4, 3, 1, 4, 0, 4, 4])\n",
      "OUTPUT:  tensor([2, 3, 4, 4, 3, 2, 1, 2, 1, 3, 1, 4, 0, 2, 1, 4, 4, 1, 0, 4, 0, 1, 3, 1,\n",
      "        2, 1, 3, 1, 4, 0, 2, 2])\n",
      "Accuracy after  50 steps:  0.894375\n",
      "Precision, recall =  tensor(0.8484) tensor(0.8773)\n",
      "TARGET:  tensor([1, 2, 3, 2, 0, 4, 3, 0, 0, 1, 0, 0, 1, 2, 0, 4, 2, 4, 2, 3, 0, 0, 0, 0,\n",
      "        3, 4, 1, 0, 3, 0, 3, 0])\n",
      "OUTPUT:  tensor([1, 4, 3, 2, 0, 4, 3, 3, 0, 1, 0, 0, 1, 2, 0, 4, 2, 4, 2, 3, 1, 0, 1, 4,\n",
      "        3, 4, 1, 0, 2, 0, 3, 0])\n",
      "Accuracy after  100 steps:  0.8840625\n",
      "Precision, recall =  tensor(0.7933) tensor(0.8651)\n",
      "Epoch:  14 Loss:  1.1894010294927284  Accuracy:  94.62053571428571 Matthews corr.coef:  tensor(0.9560) Cohen Kappa metric on train tensor(0.9545)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|  | 15/20 [1:22:37<27:34, 330.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([3, 4, 3, 1, 1, 4, 2, 4, 1, 0, 2, 0, 2, 1, 1, 4, 4, 1, 3, 4, 4, 4, 4, 4,\n",
      "        3, 4, 1, 4, 4, 3, 1, 4])\n",
      "OUTPUT:  tensor([3, 4, 3, 1, 1, 4, 2, 4, 1, 0, 2, 1, 2, 1, 1, 4, 4, 1, 3, 2, 3, 4, 4, 4,\n",
      "        3, 4, 1, 4, 4, 3, 1, 4])\n",
      "Accuracy after  50 steps:  0.905\n",
      "Precision, recall =  tensor(0.8944) tensor(0.8714)\n",
      "TARGET:  tensor([4, 2, 1, 4, 2, 3, 0, 2, 0, 3, 0, 3, 1, 3, 4, 1, 1, 4, 4, 4, 1, 2, 1, 0,\n",
      "        2, 3, 1, 3, 4, 0, 1, 1])\n",
      "OUTPUT:  tensor([4, 2, 1, 4, 2, 3, 0, 2, 0, 3, 0, 3, 1, 3, 4, 1, 1, 2, 4, 4, 1, 2, 1, 0,\n",
      "        2, 3, 1, 3, 0, 0, 1, 1])\n",
      "Accuracy after  100 steps:  0.89125\n",
      "Precision, recall =  tensor(0.9333) tensor(0.9429)\n",
      "Epoch:  15 Loss:  1.210853899812459  Accuracy:  95.08928571428571 Matthews corr.coef:  tensor(0.6486) Cohen Kappa metric on train tensor(0.6370)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 16/20 [1:28:07<22:03, 330.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([1, 1, 4, 3, 1, 4, 0, 4, 4, 2, 1, 0, 4, 2, 3, 1, 2, 1, 2, 3, 1, 1, 3, 3,\n",
      "        2, 2, 4, 0, 2, 1, 2, 1])\n",
      "OUTPUT:  tensor([1, 1, 3, 3, 1, 4, 0, 4, 2, 0, 1, 0, 4, 2, 3, 1, 2, 1, 2, 3, 1, 1, 3, 3,\n",
      "        2, 2, 4, 0, 4, 1, 2, 1])\n",
      "Accuracy after  50 steps:  0.896875\n",
      "Precision, recall =  tensor(0.8481) tensor(0.8833)\n",
      "TARGET:  tensor([2, 2, 1, 0, 1, 2, 0, 4, 2, 0, 4, 1, 2, 4, 4, 4, 1, 1, 1, 3, 0, 0, 3, 0,\n",
      "        4, 2, 3, 4, 0, 4, 1, 4])\n",
      "OUTPUT:  tensor([2, 2, 1, 0, 1, 2, 0, 4, 2, 0, 4, 1, 2, 1, 4, 4, 1, 1, 1, 3, 0, 0, 3, 0,\n",
      "        4, 2, 3, 3, 0, 3, 1, 2])\n",
      "Accuracy after  100 steps:  0.885625\n",
      "Precision, recall =  tensor(0.8664) tensor(0.9111)\n",
      "Epoch:  16 Loss:  1.2335589545712407  Accuracy:  94.64732142857143 Matthews corr.coef:  tensor(0.9145) Cohen Kappa metric on train tensor(0.9101)\n",
      "Validating.....\n",
      "Validation accuracy:  0.7935267857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%| | 17/20 [1:33:38<16:32, 330.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([0, 1, 3, 0, 1, 4, 3, 0, 1, 2, 3, 1, 1, 2, 3, 3, 4, 1, 0, 0, 4, 1, 2, 4,\n",
      "        1, 4, 4, 2, 1, 4, 4, 1])\n",
      "OUTPUT:  tensor([0, 3, 3, 0, 1, 4, 3, 0, 1, 2, 3, 1, 1, 2, 3, 3, 4, 1, 0, 0, 2, 1, 2, 2,\n",
      "        1, 4, 4, 2, 1, 4, 4, 1])\n",
      "Accuracy after  50 steps:  0.913125\n",
      "Precision, recall =  tensor(0.9000) tensor(0.9300)\n",
      "TARGET:  tensor([0, 3, 1, 3, 4, 3, 1, 3, 3, 2, 4, 1, 1, 0, 2, 2, 3, 4, 1, 1, 2, 3, 1, 0,\n",
      "        2, 4, 3, 4, 3, 2, 4, 3])\n",
      "OUTPUT:  tensor([0, 3, 1, 0, 4, 3, 1, 3, 3, 2, 4, 1, 1, 0, 0, 4, 3, 2, 1, 1, 2, 3, 1, 0,\n",
      "        2, 4, 3, 4, 3, 2, 4, 3])\n",
      "Accuracy after  100 steps:  0.8928125\n",
      "Precision, recall =  tensor(0.8467) tensor(0.8800)\n",
      "Epoch:  17 Loss:  1.2192161910601758  Accuracy:  95.48214285714286 Matthews corr.coef:  tensor(0.8306) Cohen Kappa metric on train tensor(0.8170)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%| | 18/20 [1:39:09<11:01, 330.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([1, 1, 3, 4, 4, 0, 4, 0, 1, 2, 2, 4, 1, 2, 4, 4, 0, 1, 1, 2, 4, 4, 0, 4,\n",
      "        3, 1, 3, 4, 2, 4, 4, 2])\n",
      "OUTPUT:  tensor([1, 1, 3, 4, 4, 0, 1, 0, 1, 2, 2, 4, 1, 2, 4, 4, 0, 1, 1, 2, 4, 4, 0, 4,\n",
      "        3, 1, 3, 4, 2, 4, 4, 2])\n",
      "Accuracy after  50 steps:  0.898125\n",
      "Precision, recall =  tensor(0.9750) tensor(0.9833)\n",
      "TARGET:  tensor([1, 4, 4, 1, 4, 1, 3, 2, 0, 4, 0, 1, 4, 2, 1, 2, 1, 2, 1, 1, 3, 0, 3, 4,\n",
      "        1, 1, 3, 4, 4, 0, 2, 2])\n",
      "OUTPUT:  tensor([1, 4, 4, 1, 4, 1, 3, 2, 0, 2, 0, 1, 4, 2, 1, 2, 4, 2, 1, 1, 3, 0, 3, 4,\n",
      "        0, 1, 3, 4, 4, 0, 2, 2])\n",
      "Accuracy after  100 steps:  0.891875\n",
      "Precision, recall =  tensor(0.9064) tensor(0.9350)\n",
      "Epoch:  18 Loss:  1.3480417372193187  Accuracy:  95.04464285714286 Matthews corr.coef:  tensor(0.8250) Cohen Kappa metric on train tensor(0.8196)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|| 19/20 [1:44:39<05:30, 330.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([4, 2, 1, 2, 0, 1, 1, 1, 4, 1, 4, 2, 1, 1, 4, 2, 2, 3, 4, 3, 2, 4, 2, 4,\n",
      "        1, 1, 2, 0, 0, 0, 2, 3])\n",
      "OUTPUT:  tensor([4, 2, 1, 2, 0, 1, 1, 1, 4, 1, 4, 2, 1, 1, 4, 2, 2, 3, 4, 3, 2, 4, 2, 4,\n",
      "        1, 1, 2, 0, 0, 2, 0, 3])\n",
      "Accuracy after  50 steps:  0.89875\n",
      "Precision, recall =  tensor(0.9278) tensor(0.9278)\n",
      "TARGET:  tensor([0, 2, 1, 1, 4, 1, 2, 4, 1, 2, 3, 3, 4, 3, 2, 1, 1, 4, 2, 1, 2, 0, 3, 0,\n",
      "        0, 3, 4, 2, 1, 0, 1, 3])\n",
      "OUTPUT:  tensor([0, 4, 1, 1, 4, 1, 2, 4, 1, 2, 3, 3, 4, 3, 0, 1, 1, 4, 2, 1, 2, 4, 3, 1,\n",
      "        1, 3, 4, 2, 1, 0, 1, 3])\n",
      "Accuracy after  100 steps:  0.8846875\n",
      "Precision, recall =  tensor(0.8398) tensor(0.8229)\n",
      "Epoch:  19 Loss:  1.2613357033613803  Accuracy:  94.70535714285714 Matthews corr.coef:  tensor(0.8634) Cohen Kappa metric on train tensor(0.8605)\n",
      "Validating.....\n",
      "Validation accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [1:50:11<00:00, 330.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Cohen Kappa</td><td></td></tr><tr><td>Epochs</td><td></td></tr><tr><td>F1 score_train: </td><td></td></tr><tr><td>Matthews corr.coef: </td><td></td></tr><tr><td>Train accuracy</td><td></td></tr><tr><td>Validation accuracy</td><td></td></tr><tr><td>precision</td><td></td></tr><tr><td>recall</td><td></td></tr><tr><td>train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Cohen Kappa</td><td>0.86047</td></tr><tr><td>Epochs</td><td>19</td></tr><tr><td>F1 score_train: </td><td>0.89286</td></tr><tr><td>Matthews corr.coef: </td><td>0.86341</td></tr><tr><td>Train accuracy</td><td>94.70536</td></tr><tr><td>Validation accuracy</td><td>0.82812</td></tr><tr><td>precision</td><td>0.91333</td></tr><tr><td>recall</td><td>0.86</td></tr><tr><td>train_loss</td><td>1.26134</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wandering-sun-2</strong>: <a href=\"https://wandb.ai/artyom9090/Provectus_classification_flowers/runs/27f17avm\" target=\"_blank\">https://wandb.ai/artyom9090/Provectus_classification_flowers/runs/27f17avm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220613_024116-27f17avm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_efficient = model_pipeline(config, train_loader, valid_loader, efficient_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0f9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
